# ğŸ¥ AI-Powered Doctor Triage Chatbot

This project is a **FastAPI-based intelligent healthcare chatbot** that simulates a **virtual doctor** capable of collecting patient symptoms, performing **triage evaluation**, and providing guideline-based recommendations.
It integrates **pre-trained AI models (via Ollama API)** and multiple logic modules for structured data extraction, triage evaluation, and medical guideline verification.

---

## ğŸš€ Features

* ğŸ” **Secure authentication** using JWT & password hashing
* ğŸ¤– **AI Doctor Agent** â€” generates empathetic medical replies
* ğŸ§  **Symptom Extractor** â€” turns chat into structured symptom data
* âš•ï¸ **Triage Engine** â€” classifies condition as Emergency/Urgent/Routine
* ğŸ“š **Guideline Verifier** â€” adjusts triage using medical guidelines
* ğŸ’¾ **MongoDB Atlas Integration** for users and logs
* ğŸŒ **FastAPI Backend + Static Frontend** for easy web use

---

## ğŸ§© Project Structure

```
â”œâ”€â”€ main.py                     # FastAPI entry point
â”œâ”€â”€ doctor_agent.py             # AI doctor conversational logic
â”œâ”€â”€ symptom_extractor.py        # Extracts structured data from chat
â”œâ”€â”€ triage_engine.py            # Determines urgency level
â”œâ”€â”€ guideline_verifier.py       # Verifies triage per medical rules
â”œâ”€â”€ utils.py                    # Logging, constants, helper functions
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ login.html
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ data/
â”‚   â””â”€â”€ guidelines.json         # Medical guideline reference
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ **Clone the repository**

```bash
git clone https://github.com/shivareddy6351/doctor-triage-ollama.git
cd doctor-triage-chatbot
```

### 2ï¸âƒ£ **Create a virtual environment**

```bash
python -m venv venv
venv\Scripts\activate      # (Windows)
source venv/bin/activate   # (Mac/Linux)
```

### 3ï¸âƒ£ **Install dependencies**

```bash
pip install -r requirements.txt
```

## ğŸ”‘ Environment Variables (.env file)

Create a `.env` file in the project root with:

```
MONGO_URL=mongodb+srv://<user>:<password>@cluster.mongodb.net/
SECRET_KEY=your_secret_key
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
OLLAMA_URL=http://localhost:11434
MODEL_NAME=llama3:instruct
APP_PORT=8000
```

> ğŸ’¡ Ensure your **Ollama model** is running locally or accessible from the given URL.

---

## ğŸ§  Running the Application

Run the FastAPI app:

```bash
uvicorn main:app --reload
```

Then open your browser:

```
http://127.0.0.1:8000
```

âœ… **Login Page:**
Youâ€™ll first see `login.html` for user authentication.

âœ… **Chat Interface:**
After login, `/chat` opens the AI Doctor Chat interface.

---

## ğŸ©º Usage Flow

1. **User registers or logs in** â€” JWT authentication is generated.
2. **User enters symptoms** â€” message sent to `/api/chat`.
3. **Doctor agent (AI model)** replies using Ollama LLM.
4. **Symptom Extractor** processes the full conversation into structured data.
5. **Triage Engine** evaluates if the case is Emergency, Urgent, or Routine.
6. **Guideline Verifier** upgrades triage based on `guidelines.json`.
7. **Session Logs** are stored via `utils.log_session()`.
8. The final AI reply + triage result is sent back to the frontend.

---

## ğŸ—ï¸ Architecture Overview

**Frontend:** Static HTML/CSS (served by FastAPI)
**Backend:** FastAPI REST API
**Modules:**

* `doctor_agent.py` â†’ calls AI model for conversational reply
* `symptom_extractor.py` â†’ extracts structured data
* `triage_engine.py` â†’ checks severity level
* `guideline_verifier.py` â†’ adjusts based on guidelines
* `utils.py` â†’ logs sessions, manages constants

**Database:** MongoDB Atlas
**AI Model:** Pre-trained model via Ollama API (e.g., LLaMA, Mistral, etc.)

---

## ğŸ§¾ Logging

Each chat session is logged:

```
/logs/session_<session_id>.json
```

It includes:

* Chat messages
* Extracted structured data
* Triage result
* Timestamp

---

## ğŸ“Š Example Output

```json
{
  "reply": "Based on your symptoms, it may be a mild infection. Keep hydrated and rest.",
  "structured": {
    "chief_complaint": "fever and sore throat",
    "onset": "2 days",
    "severity": "moderate",
    "associated_symptoms": ["fatigue"],
    "vitals": {"temp": "38.5"}
  },
  "triage": {"level": "Urgent", "reason": "High fever detected."}
}
```

---

## ğŸ§¾ Execution Details (Step-by-Step)

1. **Start Ollama model server**
   Example (if using LLaMA 3 model):

   ```bash
   ollama run llama3:instruct
   ```

2. **Run FastAPI app**

   ```bash
   uvicorn main:app --reload
   ```

3. **Access the app**

   * Visit `http://127.0.0.1:8000`
   * Register â†’ Login â†’ Start chatting

4. **Each message triggers:**

   * Doctor agent reply (AI)
   * Symptom extraction
   * Triage evaluation
   * Guideline verification
   * Logging of session data

5. **Results are displayed instantly** on the frontend.

---

## ğŸ§© Team & Project Details

* **Team ID:** G459
* **Project Title:** *AI Agents for Conversational Patient Triage*
* **Member:** *Shiva Vardhan Markala (22BD1A6736)*

---

## ğŸ“˜ License

Released under the **MIT License** â€” free to use, modify, and extend.

---
